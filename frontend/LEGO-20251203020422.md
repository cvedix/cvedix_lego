# Detail system architecture and tech stack

## CvedixLego: Visual Flow-Based AI Video Analytics Pipeline Platform

**Technical Architecture Document**
Quan Nguyen | 20/11/2025

---

## Table of Contents

1. Executive Summary
2. System Architecture Overview
3. Backend Architecture (C++)
4. Frontend Architecture (React + Vite)
5. Node System Design
6. Communication Layer
7. Data Flow Architecture
8. HTML File Demo
9. Docx format of this doc (export)

---

## 1\. Executive Summary

### Project Overview

CvedixLego is a visual flow-based pipeline-building platform designed for computer vision AI applications, video processing, and sensor-data automation. The system enables users to create sophisticated CV processing pipelines through a drag-and-drop interface without writing complex code, democratizing access to advanced computer vision capabilities.

### Core Objectives

- **Modular Architecture**: Each component functions as a reusable block (camera, detector, tracker, AI model, encoder, MQTT, RTSP).
- **Low-Code Interface**: Visual node-based programming similar to n8n and Diffy workflows.
- **Real-Time Processing**: Support for RTSP streams, USB cameras, and real-time AI inference.
- **Service Integration**: Leverage existing C++ services for face detection, anomaly detection, vehicle tracking, and counting.
- **Extensibility**: Easy addition of new nodes and AI models without system-wide changes, with support for copying templates or configurations via JSON format.

---

## 2\. System Architecture Overview

### High-Level Architecture

The system follows a 3-layer architecture with clear separation of concerns:

- **Presentation Layer (Frontend)**:

React + Vite SPA with ReactFlow for node-based canvas. Handles user interactions, pipeline visualization, and node configuration.

- **Application Layer (Backend API)**:

C++ REST API server with WebSocket support. Manages pipeline orchestration, node lifecycle, and service coordination.

- **Service Layer (Processing Services)**:

Existing C++ services for video capture, AI inference, and data output. Handles actual CV processing workloads.

---

### Technology Stack

| Component          | Technology              | Purpose                           |
| ------------------ | ----------------------- | --------------------------------- |
| Frontend Framework | React 18 + Vite 5       | UI rendering and state management |
| Node Canvas        | ReactFlow               | Visual flow editor                |
| Backend Server     | C++20 with Boost.Beast  | HTTP/WebSocket server             |
| API Communication  | REST + gRPC + WebSocket | Multi-protocol support            |
| CV Processing      | Edge AI SDK C++         | Video processing and AI inference |
| Data Serialization | JSON (nlohmann/json)    | Pipeline and result formatting    |
| State Management   | React Query, Redux      | Frontend state and data fetching  |

---

## 3\. Backend Architecture (C++)

### 3.1 Core Components

- **API Gateway Layer**: Entry point for all frontend requests. Handles HTTP/HTTPS, WebSocket connections, and gRPC endpoints. Built with Boost.Beast for high-performance async I/O.
- **Pipeline Orchestrator**: Manages the lifecycle of processing pipelines, including creation, validation, execution, monitoring, and termination.
- **Node Manager**: Registry and factory for all node types. Handles node instantiation, configuration, and inter-node communication.
- **Service Connector**: Abstraction layer over existing C++ services. Provides a uniform interface to RTSP readers, USB camera handlers, AI detection services, and output modules.
- **Resource Manager**: Monitors and allocates system resources (CPU, GPU, memory). Implements throttling and queue management for multiple concurrent pipelines.

---

### 3.2 Key Backend Classes

- **BaseNode Interface**: Abstract base class for all nodes, defining methods like `initialize()`, `process()`, `getInputs()`, and `getOutputs()`.
- **PipelineGraph**: Directed acyclic graph (DAG) representing node connections, with cycle detection and execution scheduling.
- **DataPacket**: Shared data structure passed between nodes, containing frame data, metadata, and detection results.
- **ExecutionContext**: Runtime context for pipeline execution, managing state, thread pools, and error handling.

---

### 3.3 API Endpoints

/

| Endpoint                    | Method | Purpose                   |
| --------------------------- | ------ | ------------------------- |
| `/api/nodes`                | GET    | List available node types |
| `/api/pipeline`             | POST   | Create new pipeline       |
| `/api/pipeline/{id}`        | PUT    | Update pipeline           |
| `/api/pipeline/{id}/start`  | POST   | Start pipeline execution  |
| `/api/pipeline/{id}/stop`   | POST   | Stop pipeline execution   |
| `/api/pipeline/{id}/status` | GET    | Get pipeline status       |
| `/api/templates`            | GET    | Get pipeline templates    |
| `/api/nodes/upload-video`   | POST   | Upload A Video file       |
|                             | MQTT   | Stream response           |

---

## 4\. Frontend Architecture (React + Vite)

### 4.1 Core Frontend Components

- **FlowCanvas**: Main canvas component using ReactFlow for node drag-and-drop, connection creation, and canvas interactions.
- **Node Components**: Custom renderers for each node type (Source, Processing, Output), supporting inline editing for quick parameter adjustments.
- **NodePalette**: Sidebar displaying available nodes, with drag-to-canvas functionality and search/filter capabilities.
- **ConfigPanel**: Properties panel for selected node configuration, with dynamic form fields and real-time validation.
- **Toolbar**: Action buttons for pipeline operations (save, load, start, stop, export) and execution metrics display.

---

# 5\. Node System Design

## 5.1 Node Categories

### Source Nodes (Input)

- **RTSP Camera**: Connect to IP cameras via RTSP protocol. Configurable: URL, resolution, FPS, codec.
- **USB Camera**: Local USB webcam input. Configurable: device ID, resolution, exposure.
- **Video File**: Load video from disk. Configurable: file path, loop playback, start frame.
- **Image Sequence**: Load series of images. Configurable: directory path, pattern, FPS.

### Processing Nodes (AI & Transformation)

- **Face Detection**: Detect faces in frames. Configurable: model type (Haar/DNN), confidence threshold, tracking.
- **Object Detection**: YOLO-based detection. Configurable: model version, classes, NMS threshold, confidence.
- **Vehicle Counter**: Count vehicles crossing line. Configurable: counting line coordinates, direction, vehicle types.
- **Anomaly Detection**: Detect abnormal events. Configurable: sensitivity, learning rate, alert threshold.
- **ROI Selector**: Define regions of interest. Configurable: polygon coordinates, multiple ROIs.
- **Object Tracker**: Track detected objects. Configurable: tracker type (SORT/DeepSORT), max age, min hits.
- **Frame Preprocessor**: Resize, crop, normalize. Configurable: dimensions, normalization params.

Input more supported AI Tasks by Cvedix here...

### Output Nodes (Export & Integration)

- **JSON Output**: Export detections as JSON. Configurable: format schema, output destination.
- **MQTT Publisher**: Send results to MQTT broker. Configurable: broker URL, topic, QoS.
- **RTSP Server**: Stream annotated video. Configurable: port, codec, bitrate.
- **Video Recorder**: Save processed video. Configurable: output path, codec, quality.
- **HTTP Webhook**: POST results to endpoint. Configurable: URL, headers, retry logic.
- **Database Writer**: Store to SQL/NoSQL. Configurable: connection string, table schema.
- **SSE Streamer**: Stream results directly via Server-Sent Events. Configurable: endpoint, retry interval.
- **Websocket Streamer:** Alternative to SSE

## 5.2 Node Schema Definition

Each node is defined by a JSON schema specifying its properties:

- **Node Metadata**: ID, name, category, version, description.
- **Input Ports**: Data types accepted, port names, required/optional flags.
- **Output Ports**: Data types produced, port names, multiplicity.
- **Configuration Parameters**: Type, default value, validation rules, UI hints.
- **Resource Requirements**: CPU cores, GPU memory, max throughput.

# 6\. Communication Layer

## 6.1 Protocol Selection

- **REST HTTP/HTTPS**: For pipeline CRUD operations, node configuration, template management, and file uploads. Stateless, cacheable, and widely supported.
- **WebSocket/Server-Sent Events**: For real-time status updates, pipeline execution logs, and live detection streaming. Enables bidirectional, low-latency communication.
- **gRPC**: For backend-to-service communication and high-throughput data transfer. Efficient binary protocol with HTTP/2 and Protocol Buffers.
- **HTTP Streaming (SSE)**: For one-way video frame streaming and detection results feed. Simple, firewall-friendly, and supports automatic reconnection.

## 6.2 Message Formats

- **Pipeline Definition (JSON)**: Contains nodes array with IDs, types, positions, configurations, and edges array defining connections between node ports.
- **Detection Result (JSON)**: Includes frame metadata (timestamp, frame ID) and detections array with bounding boxes, confidence scores, class labels, and tracking information.
- **Status Update (WebSocket/SSE)**: Provides pipeline state (running/paused/stopped), node status, FPS metrics, error messages, and resource utilization.

# 7\. Data Flow Architecture

## 7.1 Pipeline Execution Flow

1. User creates a pipeline in the frontend canvas by dragging nodes and connecting them.
2. Frontend validates the pipeline (DAG check, type compatibility) and sends it to the backend via POST `/api/pipeline`.
3. Backend validates, performs topological sorting, and stores the pipeline definition in memory/database.
4. User clicks 'Start,' triggering POST `/api/pipeline/{id}/start`.
5. Execution engine creates an `ExecutionContext` and initializes all nodes in topological order.
6. Source nodes begin frame capture and push `DataPackets` to connected nodes via queues.
7. Processing nodes consume input packets, execute AI/CV operations, and produce output packets.
8. Output nodes receive final results and export them to configured destinations.
9. Status updates are streamed to the frontend via WebSocket for live monitoring.

## 7 .2 Data Passing Mechanisms

- **Shared Memory (Zero-Copy)**: Used for large video frames to avoid copying `cv::Mat` data between nodes. Implements reference counting for lifetime management.
- **Message Queues**: Lock-free queues (e.g., `boost::lockfree::queue`) handle small metadata and detection results. Each edge has a dedicated queue.
- **Thread Pool**: Nodes execute in a thread pool to maximise CPU utilisation. Parallelism is configurable based on dependencies and available cores.

# Conclusion

CvedixLego represents a comprehensive platform for visual computer vision pipeline development. By leveraging existing C++ services and providing an intuitive drag-and-drop interface, the system democratizes access to advanced CV capabilities while maintaining the flexibility and performance required for production deployments.

The modular architecture ensures easy extensibility, allowing new nodes and AI models to be integrated without system-wide changes. The multi-protocol communication layer provides flexibility for different use cases, from real-time monitoring to batch processing.

# Appendix A: Example Pipeline JSON

This example shows a simple face detection pipeline configuration that can be...

# Have this doc in docx format:

[CvedixLego_Technical_Document.docx](https://t90181452478.p.clickup-attachments.com/t90181452478/73b7ebb7-67f6-41da-ab91-100779bbff56/CvedixLego_Technical_Document.docx)
